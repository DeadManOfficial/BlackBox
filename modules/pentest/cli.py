"""
CLI Interface for DeadMan Pen.

Command-line interface for running autonomous penetration tests.
"""

import asyncio
import argparse
import sys
import json
from pathlib import Path
from datetime import datetime

from .orchestrator import Orchestrator, OrchestratorConfig


def create_parser() -> argparse.ArgumentParser:
    """Create argument parser."""
    parser = argparse.ArgumentParser(
        prog='deadman-pen',
        description='DeadMan Pen - Autonomous If/Then Pentest Orchestrator',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s example.com
  %(prog)s example.com --resume
  %(prog)s example.com --config stealth.yaml
  %(prog)s example.com --output report.json
  %(prog)s --list-assessments
  %(prog)s --status 1
        """
    )

    # Target
    parser.add_argument(
        'target',
        nargs='?',
        help='Target domain or URL to assess'
    )

    # Execution options
    parser.add_argument(
        '--resume', '-r',
        action='store_true',
        help='Resume previous assessment for target'
    )

    parser.add_argument(
        '--config', '-c',
        type=str,
        default='G:/deadman-pen/config.yaml',
        help='Path to configuration file'
    )

    parser.add_argument(
        '--db', '-d',
        type=str,
        default='G:/deadman-pen/state.db',
        help='Path to state database'
    )

    # Output options
    parser.add_argument(
        '--output', '-o',
        type=str,
        help='Export report to file (JSON format)'
    )

    parser.add_argument(
        '--quiet', '-q',
        action='store_true',
        help='Minimal output'
    )

    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Verbose output'
    )

    # Constraint options
    parser.add_argument(
        '--safe-mode',
        action='store_true',
        default=True,
        help='Enable safe mode (default: True)'
    )

    parser.add_argument(
        '--no-safe-mode',
        action='store_true',
        help='Disable safe mode'
    )

    parser.add_argument(
        '--rate-limit',
        type=float,
        default=10.0,
        help='Requests per second (default: 10)'
    )

    parser.add_argument(
        '--max-workers',
        type=int,
        default=10,
        help='Maximum concurrent workers (default: 10)'
    )

    # Management commands
    parser.add_argument(
        '--list-assessments',
        action='store_true',
        help='List all assessments'
    )

    parser.add_argument(
        '--status',
        type=int,
        metavar='ID',
        help='Show status for assessment ID'
    )

    parser.add_argument(
        '--export',
        type=int,
        metavar='ID',
        help='Export assessment ID to JSON'
    )

    parser.add_argument(
        '--delete',
        type=int,
        metavar='ID',
        help='Delete assessment by ID'
    )

    # Goal configuration
    parser.add_argument(
        '--access-goal',
        choices=['anonymous', 'user', 'admin', 'root'],
        default='admin',
        help='Target access level (default: admin)'
    )

    return parser


async def run_assessment(args: argparse.Namespace) -> int:
    """Run an assessment."""
    config = OrchestratorConfig(
        db_path=args.db,
        config_path=args.config,
        max_workers=args.max_workers,
        rate_limit_rps=args.rate_limit,
        safe_mode=not args.no_safe_mode,
        verbose=args.verbose and not args.quiet,
    )

    orchestrator = Orchestrator(config)

    if not args.quiet:
        print(f"\n{'=' * 60}")
        print("DEADMAN PEN - Autonomous Pentest Orchestrator")
        print(f"{'=' * 60}")
        print(f"Target: {args.target}")
        print(f"Resume: {args.resume}")
        print(f"Safe Mode: {config.safe_mode}")
        print(f"Rate Limit: {config.rate_limit_rps} rps")
        print(f"Workers: {config.max_workers}")
        print(f"{'=' * 60}\n")

    try:
        result = await orchestrator.run(
            target=args.target,
            resume=args.resume
        )

        # Print results
        if not args.quiet:
            print(f"\n{'=' * 60}")
            print("ASSESSMENT COMPLETE")
            print(f"{'=' * 60}")
            print(f"Target: {result.target}")
            print(f"Status: {result.status}")
            print(f"Duration: {result.duration_seconds:.1f}s")
            print(f"Phases: {', '.join(result.phases_completed)}")
            print(f"Access: {result.access_achieved.name}")
            print(f"Findings: {len(result.findings)}")
            print(f"Assets: {len(result.assets_acquired)}")

            # Findings by severity
            severity_counts = {}
            for finding in result.findings:
                sev = finding.severity.value if hasattr(finding.severity, 'value') else str(finding.severity)
                severity_counts[sev] = severity_counts.get(sev, 0) + 1

            if severity_counts:
                print(f"\nFindings by Severity:")
                for sev in ['critical', 'high', 'medium', 'low', 'info']:
                    if sev in severity_counts:
                        print(f"  {sev.upper()}: {severity_counts[sev]}")

            # Bounty matches
            if result.bounty_matches:
                print(f"\nBounty Matches: {', '.join(result.bounty_matches)}")

            # Goals
            print(f"\nGoals:")
            for goal, status in result.goals_summary.get('goal_status', {}).items():
                status_str = status['status']
                pct = status['percentage']
                marker = '[x]' if status_str == 'completed' else '[ ]'
                print(f"  {marker} {goal}: {pct:.0f}%")

        # Export if requested
        if args.output:
            orchestrator.export_report(args.output)
            print(f"\nReport exported to: {args.output}")

        return 0

    except KeyboardInterrupt:
        print("\n\nAssessment interrupted by user")
        orchestrator.stop()
        return 130

    except Exception as e:
        print(f"\nError: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1


def list_assessments(args: argparse.Namespace) -> int:
    """List all assessments."""
    from .state import StateManager

    state = StateManager(args.db)
    assessments = state.get_all_assessments()

    if not assessments:
        print("No assessments found.")
        return 0

    print(f"\n{'ID':<6} {'Target':<30} {'Status':<12} {'Phase':<8} {'Started':<20}")
    print("-" * 80)

    for a in assessments:
        started = a['started_at'][:19] if a['started_at'] else 'N/A'
        print(f"{a['id']:<6} {a['target'][:28]:<30} {a['status']:<12} {a['current_phase']:<8} {started:<20}")

    return 0


def show_status(args: argparse.Namespace) -> int:
    """Show assessment status."""
    from .state import StateManager

    state = StateManager(args.db)
    assessment = state.get_assessment(args.status)

    if not assessment:
        print(f"Assessment {args.status} not found.")
        return 1

    findings = state.get_findings(args.status)
    access = state.get_highest_access(args.status)
    assets = state.get_assets(args.status)

    print(f"\nAssessment #{args.status}")
    print("=" * 40)
    print(f"Target: {assessment['target']}")
    print(f"Domain: {assessment['domain']}")
    print(f"Status: {assessment['status']}")
    print(f"Phase: {assessment['current_phase']}")
    print(f"Started: {assessment['started_at']}")
    print(f"Updated: {assessment['updated_at']}")
    print(f"Access: {access.name if access else 'ANONYMOUS'}")
    print(f"Findings: {len(findings)}")
    print(f"Assets: {len(assets)}")

    # Severity breakdown
    if findings:
        print("\nFindings by Severity:")
        counts = {}
        for f in findings:
            sev = f.severity.value if hasattr(f.severity, 'value') else str(f.severity)
            counts[sev] = counts.get(sev, 0) + 1
        for sev, count in sorted(counts.items()):
            print(f"  {sev}: {count}")

    return 0


def export_assessment(args: argparse.Namespace) -> int:
    """Export assessment to JSON."""
    from .state import StateManager

    state = StateManager(args.db)
    output_path = args.output or f"assessment_{args.export}.json"

    try:
        state.export_json(args.export, output_path)
        print(f"Exported assessment {args.export} to {output_path}")
        return 0
    except ValueError as e:
        print(f"Error: {e}")
        return 1


def delete_assessment(args: argparse.Namespace) -> int:
    """Delete an assessment."""
    from .state import StateManager

    state = StateManager(args.db)

    # Confirm
    response = input(f"Delete assessment {args.delete}? This cannot be undone. (y/N): ")
    if response.lower() != 'y':
        print("Cancelled.")
        return 0

    state.delete_assessment(args.delete)
    print(f"Deleted assessment {args.delete}")
    return 0


def main() -> int:
    """Main entry point."""
    parser = create_parser()
    args = parser.parse_args()

    # Handle management commands
    if args.list_assessments:
        return list_assessments(args)

    if args.status:
        return show_status(args)

    if args.export:
        return export_assessment(args)

    if args.delete:
        return delete_assessment(args)

    # Require target for assessment
    if not args.target:
        parser.print_help()
        return 1

    # Run assessment
    return asyncio.run(run_assessment(args))


if __name__ == '__main__':
    sys.exit(main())
