"""
Result Parser and Normalizer for DeadMan Pen.

Normalizes output from various MCP tools into consistent
formats for the orchestrator to consume.
"""

import re
import json
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Union
from enum import Enum
from urllib.parse import urlparse

from .state import Finding, FindingType, Severity, Asset, AssetType, AccessLevel


class TechStack(Enum):
    """Detected technology categories."""
    FRONTEND = 'frontend'
    BACKEND = 'backend'
    DATABASE = 'database'
    CLOUD = 'cloud'
    AI_ML = 'ai_ml'
    AUTH = 'auth'
    PAYMENT = 'payment'
    CMS = 'cms'


@dataclass
class DetectedTechnology:
    """A detected technology with version info."""
    name: str
    category: TechStack
    version: Optional[str] = None
    confidence: float = 1.0
    indicators: List[str] = field(default_factory=list)


@dataclass
class ExtractedEndpoint:
    """An extracted API endpoint."""
    url: str
    method: str = 'GET'
    params: List[str] = field(default_factory=list)
    auth_required: bool = False
    response_type: Optional[str] = None


@dataclass
class ExtractedSecret:
    """An extracted secret or credential."""
    type: str  # api_key, jwt, password, etc.
    value: str
    context: str
    service: Optional[str] = None


@dataclass
class ParsedResult:
    """Normalized result from tool execution."""
    tool: str
    findings: List[Finding] = field(default_factory=list)
    technologies: List[DetectedTechnology] = field(default_factory=list)
    endpoints: List[ExtractedEndpoint] = field(default_factory=list)
    secrets: List[ExtractedSecret] = field(default_factory=list)
    assets: List[Asset] = field(default_factory=list)
    access_granted: Optional[AccessLevel] = None
    raw_data: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)


class ResultParser:
    """
    Parses and normalizes results from various MCP tools.

    Handles:
    - JSON output normalization
    - Markdown parsing
    - Raw text extraction
    - Severity mapping
    - Technology detection
    - Secret extraction
    """

    # Technology detection patterns
    TECH_PATTERNS = {
        # Frontend
        'react': (TechStack.FRONTEND, r'react|jsx|__NEXT_DATA__|next\.js|nextjs'),
        'vue': (TechStack.FRONTEND, r'vue|vuex|nuxt'),
        'angular': (TechStack.FRONTEND, r'angular|ng-|@angular'),
        'svelte': (TechStack.FRONTEND, r'svelte|sveltekit'),
        'astro': (TechStack.FRONTEND, r'astro'),

        # Backend
        'nodejs': (TechStack.BACKEND, r'express|fastify|nestjs|node'),
        'python': (TechStack.BACKEND, r'django|flask|fastapi|python'),
        'ruby': (TechStack.BACKEND, r'rails|ruby|sinatra'),
        'go': (TechStack.BACKEND, r'golang|go\.'),
        'php': (TechStack.BACKEND, r'laravel|symfony|php'),

        # Database
        'supabase': (TechStack.DATABASE, r'supabase|\.supabase\.'),
        'firebase': (TechStack.DATABASE, r'firebase|firestore|firebaseio'),
        'mongodb': (TechStack.DATABASE, r'mongodb|mongoose'),
        'postgresql': (TechStack.DATABASE, r'postgres|pg\.|postgresql'),
        'mysql': (TechStack.DATABASE, r'mysql|mariadb'),

        # Cloud
        'aws': (TechStack.CLOUD, r'amazonaws|s3\.|cloudfront|lambda'),
        'gcp': (TechStack.CLOUD, r'googleapis|gcp|google\.cloud'),
        'azure': (TechStack.CLOUD, r'azure|\.microsoft\.'),
        'vercel': (TechStack.CLOUD, r'vercel|\.vercel\.'),
        'netlify': (TechStack.CLOUD, r'netlify'),

        # AI/ML
        'openai': (TechStack.AI_ML, r'openai|gpt-|chatgpt'),
        'anthropic': (TechStack.AI_ML, r'anthropic|claude'),
        'huggingface': (TechStack.AI_ML, r'huggingface|transformers'),

        # Auth
        'auth0': (TechStack.AUTH, r'auth0'),
        'clerk': (TechStack.AUTH, r'clerk\.'),
        'supabase_auth': (TechStack.AUTH, r'supabase.*auth'),
        'firebase_auth': (TechStack.AUTH, r'firebase.*auth'),

        # Payment
        'stripe': (TechStack.PAYMENT, r'stripe|pk_live_|sk_live_|pk_test_'),
        'paypal': (TechStack.PAYMENT, r'paypal'),
        'paddle': (TechStack.PAYMENT, r'paddle'),
    }

    # Secret patterns
    SECRET_PATTERNS = {
        'aws_key': r'AKIA[0-9A-Z]{16}',
        'aws_secret': r'[A-Za-z0-9/+=]{40}',
        'stripe_pk': r'pk_(live|test)_[A-Za-z0-9]{24,}',
        'stripe_sk': r'sk_(live|test)_[A-Za-z0-9]{24,}',
        'github_token': r'gh[pousr]_[A-Za-z0-9_]{36,}',
        'jwt': r'eyJ[A-Za-z0-9_-]+\.eyJ[A-Za-z0-9_-]+\.[A-Za-z0-9_-]+',
        'supabase_anon': r'eyJ[A-Za-z0-9_-]+\.eyJ[A-Za-z0-9_-]+\.[A-Za-z0-9_-]+',
        'openai_key': r'sk-[A-Za-z0-9]{48}',
        'anthropic_key': r'sk-ant-[A-Za-z0-9-]+',
        'private_key': r'-----BEGIN (RSA |EC |DSA )?PRIVATE KEY-----',
        'api_key_generic': r'["\']?api[_-]?key["\']?\s*[:=]\s*["\']?([A-Za-z0-9_-]{20,})["\']?',
        'bearer_token': r'Bearer\s+([A-Za-z0-9_-]+\.?)+',
    }

    # Severity mapping from various tool outputs
    SEVERITY_MAP = {
        'critical': Severity.CRITICAL,
        'high': Severity.HIGH,
        'medium': Severity.MEDIUM,
        'moderate': Severity.MEDIUM,
        'low': Severity.LOW,
        'info': Severity.INFO,
        'informational': Severity.INFO,
        'none': Severity.INFO,
    }

    def __init__(self):
        """Initialize the parser."""
        self._compiled_tech_patterns = {
            name: (cat, re.compile(pattern, re.IGNORECASE))
            for name, (cat, pattern) in self.TECH_PATTERNS.items()
        }
        self._compiled_secret_patterns = {
            name: re.compile(pattern)
            for name, pattern in self.SECRET_PATTERNS.items()
        }

    def parse(self, tool: str, result: Dict[str, Any], phase: str = '') -> ParsedResult:
        """
        Parse tool result into normalized format.

        Args:
            tool: Name of the tool that produced the result
            result: Raw result from tool execution
            phase: Current assessment phase

        Returns:
            ParsedResult with normalized data
        """
        # Route to specific parser based on tool category
        parser_map = {
            'nuclei': self._parse_nuclei,
            'js_analyze': self._parse_js_analysis,
            'js_analyze_batch': self._parse_js_analysis,
            'ai_security_test': self._parse_ai_security,
            'llm_redteam_scan': self._parse_llm_redteam,
            'intel_comprehensive': self._parse_intel,
            'intel_cve_search': self._parse_intel_cve,
            'intel_tech_vulns': self._parse_intel_tech,
            'backend_access_scan': self._parse_backend_access,
            'cors_scan': self._parse_cors,
            'ssrf_scan': self._parse_ssrf,
            'jwt_analyze': self._parse_jwt,
            'oauth_scan': self._parse_oauth,
            'graphql_scan': self._parse_graphql,
            'payment_security_test': self._parse_payment,
            'payment_injection_scan': self._parse_payment,
            'api_enumerate': self._parse_api_enum,
            'waf_bypass_scan': self._parse_waf_bypass,
            'race_condition_scan': self._parse_race_condition,
            'stealth_fetch': self._parse_stealth_fetch,
            'crescendo_attack': self._parse_ai_attack,
            'indirect_injection_test': self._parse_ai_attack,
            'hybrid_plan_attack': self._parse_attack_plan,
        }

        # Find matching parser
        parser_fn = None
        for prefix, fn in parser_map.items():
            if tool.startswith(prefix) or tool == prefix:
                parser_fn = fn
                break

        if parser_fn:
            parsed = parser_fn(result, phase)
        else:
            parsed = self._parse_generic(tool, result, phase)

        # Add raw data
        parsed.raw_data = result
        parsed.tool = tool

        # Extract additional technologies from raw data
        self._extract_technologies(parsed)

        # Extract secrets from raw data
        self._extract_secrets(parsed)

        return parsed

    def _parse_nuclei(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse Nuclei scan results."""
        parsed = ParsedResult(tool='nuclei_scan')

        vulnerabilities = result.get('vulnerabilities', [])
        for vuln in vulnerabilities:
            severity = self._map_severity(vuln.get('severity', 'info'))

            finding = Finding(
                phase=phase,
                tool='nuclei_scan',
                type=FindingType.VULNERABILITY,
                severity=severity,
                title=vuln.get('name', vuln.get('template-id', 'Unknown')),
                description=vuln.get('description', ''),
                evidence={
                    'matched_at': vuln.get('matched-at'),
                    'matcher_name': vuln.get('matcher-name'),
                    'extracted': vuln.get('extracted-results', []),
                    'curl_command': vuln.get('curl-command'),
                },
                cvss_score=self._extract_cvss(vuln),
                cve_ids=self._extract_cves(vuln),
                mitre_techniques=self._extract_mitre(vuln),
            )
            parsed.findings.append(finding)

        return parsed

    def _parse_js_analysis(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse JavaScript analysis results."""
        parsed = ParsedResult(tool='js_analyze')

        # Extract endpoints
        endpoints = result.get('endpoints', [])
        for ep in endpoints:
            parsed.endpoints.append(ExtractedEndpoint(
                url=ep.get('url', ep) if isinstance(ep, dict) else ep,
                method=ep.get('method', 'GET') if isinstance(ep, dict) else 'GET',
            ))

        # Extract secrets
        secrets = result.get('secrets', [])
        for secret in secrets:
            parsed.secrets.append(ExtractedSecret(
                type=secret.get('type', 'unknown'),
                value=secret.get('value', ''),
                context=secret.get('context', ''),
                service=secret.get('service'),
            ))

            # Create finding for each secret
            finding = Finding(
                phase=phase,
                tool='js_analyze',
                type=FindingType.VULNERABILITY,
                severity=Severity.HIGH if 'key' in secret.get('type', '').lower() else Severity.MEDIUM,
                title=f"Exposed {secret.get('type', 'Secret')}",
                description=f"Found {secret.get('type')} in JavaScript file",
                evidence={'context': secret.get('context', '')},
            )
            parsed.findings.append(finding)

        # Check for source maps
        if result.get('source_maps_found'):
            finding = Finding(
                phase=phase,
                tool='js_analyze',
                type=FindingType.VULNERABILITY,
                severity=Severity.MEDIUM,
                title="Source Maps Exposed",
                description="JavaScript source maps are accessible, may leak original source code",
                evidence={'source_maps': result.get('source_maps', [])},
            )
            parsed.findings.append(finding)

        return parsed

    def _parse_ai_security(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse AI security test results."""
        parsed = ParsedResult(tool='ai_security_test')

        vulnerabilities = result.get('vulnerabilities', [])
        for vuln in vulnerabilities:
            finding = Finding(
                phase=phase,
                tool='ai_security_test',
                type=FindingType.VULNERABILITY,
                severity=self._map_severity(vuln.get('severity', 'medium')),
                title=vuln.get('title', vuln.get('category', 'AI Vulnerability')),
                description=vuln.get('description', ''),
                evidence={
                    'payload': vuln.get('payload'),
                    'response': vuln.get('response'),
                    'category': vuln.get('category'),
                },
            )
            parsed.findings.append(finding)

        # Check for system prompt leak
        if result.get('system_prompt_leaked'):
            parsed.assets.append(Asset(
                type=AssetType.CONFIG,
                name='System Prompt',
                location='AI Endpoint',
                metadata={'prompt': result.get('extracted_prompt', '')},
            ))

        return parsed

    def _parse_llm_redteam(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse LLM red team scan results."""
        parsed = ParsedResult(tool='llm_redteam_scan')

        findings_data = result.get('findings', [])
        for finding_data in findings_data:
            finding = Finding(
                phase=phase,
                tool='llm_redteam_scan',
                type=FindingType.VULNERABILITY,
                severity=self._map_severity(finding_data.get('severity', 'high')),
                title=finding_data.get('vulnerability_class', 'LLM Vulnerability'),
                description=finding_data.get('description', ''),
                evidence={
                    'strategy': finding_data.get('strategy'),
                    'payload': finding_data.get('payload'),
                    'response': finding_data.get('response'),
                    'owasp_id': finding_data.get('owasp_id'),
                },
            )
            parsed.findings.append(finding)

        return parsed

    def _parse_intel(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse comprehensive intel results."""
        parsed = ParsedResult(tool='intel_comprehensive')

        # CVE results
        for cve in result.get('cves', []):
            parsed.metadata.setdefault('cves', []).append({
                'id': cve.get('id'),
                'description': cve.get('description'),
                'cvss': cve.get('cvss'),
                'published': cve.get('published'),
            })

        # Exploit results
        for exploit in result.get('exploits', []):
            parsed.metadata.setdefault('exploits', []).append({
                'title': exploit.get('title'),
                'type': exploit.get('type'),
                'platform': exploit.get('platform'),
                'url': exploit.get('url'),
            })

        # MITRE techniques
        for technique in result.get('mitre_techniques', []):
            parsed.metadata.setdefault('mitre', []).append({
                'id': technique.get('id'),
                'name': technique.get('name'),
                'tactic': technique.get('tactic'),
            })

        return parsed

    def _parse_intel_cve(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse CVE search results."""
        parsed = ParsedResult(tool='intel_cve_search')

        for cve in result.get('cves', []):
            parsed.metadata.setdefault('cves', []).append({
                'id': cve.get('id'),
                'description': cve.get('description'),
                'cvss': cve.get('cvss'),
                'published': cve.get('published'),
                'references': cve.get('references', []),
            })

        return parsed

    def _parse_intel_tech(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse technology vulnerability context."""
        parsed = ParsedResult(tool='intel_tech_vulns')

        tech = result.get('technology', '')
        version = result.get('version', '')

        # Store vulnerabilities specific to this tech
        for vuln in result.get('vulnerabilities', []):
            parsed.metadata.setdefault('tech_vulns', []).append({
                'technology': tech,
                'version': version,
                'cve': vuln.get('cve'),
                'severity': vuln.get('severity'),
                'description': vuln.get('description'),
            })

        return parsed

    def _parse_backend_access(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse backend access scan results."""
        parsed = ParsedResult(tool='backend_access_scan')

        # Check direct access vulnerabilities
        if result.get('direct_api_access'):
            finding = Finding(
                phase=phase,
                tool='backend_access_scan',
                type=FindingType.VULNERABILITY,
                severity=Severity.CRITICAL,
                title="Direct Backend API Access",
                description=f"Direct access to {result.get('service', 'backend')} API without authentication",
                evidence={
                    'service': result.get('service'),
                    'accessible_endpoints': result.get('accessible_endpoints', []),
                },
            )
            parsed.findings.append(finding)

            # Potentially grant access level
            if result.get('admin_access'):
                parsed.access_granted = AccessLevel.ADMIN
            elif result.get('user_access'):
                parsed.access_granted = AccessLevel.USER

        # Check storage access
        if result.get('storage_public'):
            finding = Finding(
                phase=phase,
                tool='backend_access_scan',
                type=FindingType.VULNERABILITY,
                severity=Severity.HIGH,
                title="Public Storage Bucket Access",
                description="Storage bucket is publicly accessible",
                evidence={
                    'buckets': result.get('public_buckets', []),
                    'files_found': result.get('files_found', []),
                },
            )
            parsed.findings.append(finding)

            # Create asset for exposed data
            if result.get('files_found'):
                parsed.assets.append(Asset(
                    type=AssetType.DATABASE,
                    name='Storage Bucket Data',
                    location=result.get('service', 'backend'),
                    metadata={'files': result.get('files_found', [])},
                ))

        return parsed

    def _parse_cors(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse CORS scan results."""
        parsed = ParsedResult(tool='cors_scan')

        if result.get('vulnerable'):
            severity = Severity.CRITICAL if result.get('credentials_allowed') else Severity.HIGH

            finding = Finding(
                phase=phase,
                tool='cors_scan',
                type=FindingType.VULNERABILITY,
                severity=severity,
                title="CORS Misconfiguration",
                description=result.get('description', 'Cross-Origin Resource Sharing misconfiguration detected'),
                evidence={
                    'misconfiguration_type': result.get('type'),
                    'origin_reflected': result.get('origin_reflected'),
                    'null_origin_allowed': result.get('null_origin_allowed'),
                    'wildcard': result.get('wildcard'),
                    'credentials_allowed': result.get('credentials_allowed'),
                },
            )
            parsed.findings.append(finding)

        return parsed

    def _parse_ssrf(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse SSRF scan results."""
        parsed = ParsedResult(tool='ssrf_scan')

        if result.get('vulnerable'):
            finding = Finding(
                phase=phase,
                tool='ssrf_scan',
                type=FindingType.VULNERABILITY,
                severity=Severity.CRITICAL,
                title="Server-Side Request Forgery",
                description=result.get('description', 'SSRF vulnerability detected'),
                evidence={
                    'parameter': result.get('parameter'),
                    'payload': result.get('payload'),
                    'accessed_internal': result.get('accessed_internal'),
                    'cloud_metadata': result.get('cloud_metadata'),
                },
            )
            parsed.findings.append(finding)

            # If cloud metadata accessed, it's a critical asset
            if result.get('cloud_metadata'):
                parsed.assets.append(Asset(
                    type=AssetType.CREDENTIALS,
                    name='Cloud Metadata',
                    location='SSRF',
                    metadata={'data': result.get('metadata_data', {})},
                ))
                # Cloud metadata often grants significant access
                parsed.access_granted = AccessLevel.ADMIN

        return parsed

    def _parse_jwt(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse JWT analysis results."""
        parsed = ParsedResult(tool='jwt_analyze')

        vulnerabilities = result.get('vulnerabilities', [])
        for vuln in vulnerabilities:
            finding = Finding(
                phase=phase,
                tool='jwt_analyze',
                type=FindingType.VULNERABILITY,
                severity=self._map_severity(vuln.get('severity', 'high')),
                title=vuln.get('title', 'JWT Vulnerability'),
                description=vuln.get('description', ''),
                evidence={
                    'attack_type': vuln.get('type'),
                    'forged_token': vuln.get('forged_token'),
                    'claims': vuln.get('claims'),
                },
            )
            parsed.findings.append(finding)

        # Check for privilege escalation via JWT
        if result.get('elevated_claims'):
            parsed.access_granted = AccessLevel.ADMIN

        return parsed

    def _parse_oauth(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse OAuth scan results."""
        parsed = ParsedResult(tool='oauth_scan')

        for vuln in result.get('vulnerabilities', []):
            finding = Finding(
                phase=phase,
                tool='oauth_scan',
                type=FindingType.VULNERABILITY,
                severity=self._map_severity(vuln.get('severity', 'high')),
                title=vuln.get('title', 'OAuth Vulnerability'),
                description=vuln.get('description', ''),
                evidence={
                    'category': vuln.get('category'),
                    'redirect_uri': vuln.get('redirect_uri'),
                    'state_handling': vuln.get('state_handling'),
                },
            )
            parsed.findings.append(finding)

        # Check for token acquisition
        if result.get('token_captured'):
            parsed.secrets.append(ExtractedSecret(
                type='oauth_token',
                value=result.get('token', ''),
                context='OAuth flow exploitation',
                service=result.get('provider'),
            ))
            parsed.access_granted = AccessLevel.USER

        return parsed

    def _parse_graphql(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse GraphQL scan results."""
        parsed = ParsedResult(tool='graphql_scan')

        # Introspection enabled
        if result.get('introspection_enabled'):
            finding = Finding(
                phase=phase,
                tool='graphql_scan',
                type=FindingType.INFO,
                severity=Severity.MEDIUM,
                title="GraphQL Introspection Enabled",
                description="GraphQL introspection is enabled, exposing the entire schema",
                evidence={
                    'types': result.get('types', [])[:10],  # First 10 types
                    'queries': result.get('queries', []),
                    'mutations': result.get('mutations', []),
                },
            )
            parsed.findings.append(finding)

            # Store schema as asset
            if result.get('schema'):
                parsed.assets.append(Asset(
                    type=AssetType.SOURCE_CODE,
                    name='GraphQL Schema',
                    location='GraphQL Endpoint',
                    metadata={'schema': result.get('schema')},
                ))

        # Other vulnerabilities
        for vuln in result.get('vulnerabilities', []):
            finding = Finding(
                phase=phase,
                tool='graphql_scan',
                type=FindingType.VULNERABILITY,
                severity=self._map_severity(vuln.get('severity', 'medium')),
                title=vuln.get('title', 'GraphQL Vulnerability'),
                description=vuln.get('description', ''),
                evidence=vuln.get('evidence', {}),
            )
            parsed.findings.append(finding)

        return parsed

    def _parse_payment(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse payment security test results."""
        parsed = ParsedResult(tool='payment_security_test')

        for vuln in result.get('vulnerabilities', []):
            finding = Finding(
                phase=phase,
                tool='payment_security_test',
                type=FindingType.VULNERABILITY,
                severity=Severity.CRITICAL,  # Payment vulns are always critical
                title=vuln.get('title', 'Payment Security Issue'),
                description=vuln.get('description', ''),
                evidence={
                    'category': vuln.get('category'),
                    'payload': vuln.get('payload'),
                    'impact': vuln.get('impact'),
                },
            )
            parsed.findings.append(finding)

        return parsed

    def _parse_api_enum(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse API enumeration results."""
        parsed = ParsedResult(tool='api_enumerate')

        # Extract endpoints
        for endpoint in result.get('endpoints', []):
            parsed.endpoints.append(ExtractedEndpoint(
                url=endpoint.get('path', endpoint),
                method=endpoint.get('method', 'GET') if isinstance(endpoint, dict) else 'GET',
                auth_required=endpoint.get('auth_required', False) if isinstance(endpoint, dict) else False,
            ))

        # Store as finding if sensitive endpoints found
        sensitive = result.get('sensitive_endpoints', [])
        if sensitive:
            finding = Finding(
                phase=phase,
                tool='api_enumerate',
                type=FindingType.INFO,
                severity=Severity.MEDIUM,
                title="Sensitive API Endpoints Discovered",
                description=f"Found {len(sensitive)} potentially sensitive endpoints",
                evidence={'endpoints': sensitive},
            )
            parsed.findings.append(finding)

        return parsed

    def _parse_waf_bypass(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse WAF bypass results."""
        parsed = ParsedResult(tool='waf_bypass_scan')

        if result.get('origin_ip'):
            finding = Finding(
                phase=phase,
                tool='waf_bypass_scan',
                type=FindingType.INFO,
                severity=Severity.HIGH,
                title="Origin IP Discovered",
                description=f"Real origin IP found behind WAF/CDN: {result.get('origin_ip')}",
                evidence={
                    'origin_ip': result.get('origin_ip'),
                    'method': result.get('discovery_method'),
                    'waf': result.get('waf_detected'),
                },
            )
            parsed.findings.append(finding)

        return parsed

    def _parse_race_condition(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse race condition scan results."""
        parsed = ParsedResult(tool='race_condition_scan')

        if result.get('vulnerable'):
            finding = Finding(
                phase=phase,
                tool='race_condition_scan',
                type=FindingType.VULNERABILITY,
                severity=Severity.HIGH,
                title="Race Condition Vulnerability",
                description=result.get('description', 'Race condition detected'),
                evidence={
                    'type': result.get('type'),  # TOCTOU, double-spend, etc.
                    'successful_races': result.get('successful_races'),
                    'timing': result.get('timing'),
                },
            )
            parsed.findings.append(finding)

        return parsed

    def _parse_stealth_fetch(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse stealth fetch results."""
        parsed = ParsedResult(tool='stealth_fetch')

        # Store page content
        parsed.metadata['content'] = result.get('content', '')
        parsed.metadata['status_code'] = result.get('status_code')
        parsed.metadata['headers'] = result.get('headers', {})

        # Extract technologies from content
        content = result.get('content', '')
        self._detect_technologies_from_content(parsed, content)

        return parsed

    def _parse_ai_attack(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse AI attack results (crescendo, indirect injection)."""
        parsed = ParsedResult(tool='ai_attack')

        if result.get('successful'):
            finding = Finding(
                phase=phase,
                tool=result.get('tool', 'ai_attack'),
                type=FindingType.VULNERABILITY,
                severity=Severity.CRITICAL,
                title=result.get('title', 'AI System Compromised'),
                description=result.get('description', ''),
                evidence={
                    'attack_type': result.get('attack_type'),
                    'turns': result.get('turns'),
                    'goal_achieved': result.get('goal'),
                    'extracted_data': result.get('extracted_data'),
                },
            )
            parsed.findings.append(finding)

            # Store extracted system prompt as asset
            if result.get('system_prompt'):
                parsed.assets.append(Asset(
                    type=AssetType.CONFIG,
                    name='AI System Prompt',
                    location='AI Endpoint',
                    metadata={'prompt': result.get('system_prompt')},
                ))

        return parsed

    def _parse_attack_plan(self, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Parse hybrid attack plan results."""
        parsed = ParsedResult(tool='hybrid_plan_attack')

        parsed.metadata['attack_path'] = result.get('path', [])
        parsed.metadata['expected_success_rate'] = result.get('success_rate')
        parsed.metadata['steps'] = result.get('steps', [])

        return parsed

    def _parse_generic(self, tool: str, result: Dict[str, Any], phase: str) -> ParsedResult:
        """Generic parser for unknown tools."""
        parsed = ParsedResult(tool=tool)

        # Try to extract common patterns
        if 'vulnerabilities' in result:
            for vuln in result['vulnerabilities']:
                finding = Finding(
                    phase=phase,
                    tool=tool,
                    type=FindingType.VULNERABILITY,
                    severity=self._map_severity(vuln.get('severity', 'medium')),
                    title=vuln.get('title', vuln.get('name', 'Unknown')),
                    description=vuln.get('description', str(vuln)),
                    evidence=vuln,
                )
                parsed.findings.append(finding)

        if 'findings' in result:
            for finding_data in result['findings']:
                finding = Finding(
                    phase=phase,
                    tool=tool,
                    type=FindingType.INFO,
                    severity=self._map_severity(finding_data.get('severity', 'info')),
                    title=finding_data.get('title', 'Finding'),
                    description=finding_data.get('description', str(finding_data)),
                    evidence=finding_data,
                )
                parsed.findings.append(finding)

        return parsed

    def _map_severity(self, severity_str: str) -> Severity:
        """Map severity string to Severity enum."""
        return self.SEVERITY_MAP.get(severity_str.lower(), Severity.INFO)

    def _extract_cvss(self, data: Dict[str, Any]) -> Optional[float]:
        """Extract CVSS score from data."""
        for key in ['cvss', 'cvss_score', 'cvss-score', 'cvss3']:
            if key in data:
                try:
                    return float(data[key])
                except (ValueError, TypeError):
                    pass
        return None

    def _extract_cves(self, data: Dict[str, Any]) -> List[str]:
        """Extract CVE IDs from data."""
        cves = []

        # Check common fields
        for key in ['cve', 'cves', 'cve-id', 'cve_id']:
            if key in data:
                value = data[key]
                if isinstance(value, str):
                    cves.append(value)
                elif isinstance(value, list):
                    cves.extend(value)

        # Extract from text
        text = json.dumps(data)
        cve_pattern = re.compile(r'CVE-\d{4}-\d{4,}', re.IGNORECASE)
        cves.extend(cve_pattern.findall(text))

        return list(set(cves))

    def _extract_mitre(self, data: Dict[str, Any]) -> List[str]:
        """Extract MITRE ATT&CK technique IDs from data."""
        techniques = []

        # Check common fields
        for key in ['mitre', 'attack', 'technique', 'techniques', 'mitre_attack']:
            if key in data:
                value = data[key]
                if isinstance(value, str):
                    techniques.append(value)
                elif isinstance(value, list):
                    techniques.extend(value)

        # Extract from text
        text = json.dumps(data)
        mitre_pattern = re.compile(r'T\d{4}(?:\.\d{3})?', re.IGNORECASE)
        techniques.extend(mitre_pattern.findall(text))

        return list(set(techniques))

    def _extract_technologies(self, parsed: ParsedResult) -> None:
        """Extract technologies from parsed result data."""
        text = json.dumps(parsed.raw_data).lower()
        self._detect_technologies_from_content(parsed, text)

    def _detect_technologies_from_content(self, parsed: ParsedResult, content: str) -> None:
        """Detect technologies from content string."""
        content_lower = content.lower()

        for tech_name, (category, pattern) in self._compiled_tech_patterns.items():
            if pattern.search(content_lower):
                # Check if already detected
                existing = [t for t in parsed.technologies if t.name == tech_name]
                if not existing:
                    parsed.technologies.append(DetectedTechnology(
                        name=tech_name,
                        category=category,
                        confidence=0.8,
                        indicators=[pattern.pattern],
                    ))

    def _extract_secrets(self, parsed: ParsedResult) -> None:
        """Extract secrets from parsed result data."""
        text = json.dumps(parsed.raw_data)

        for secret_type, pattern in self._compiled_secret_patterns.items():
            matches = pattern.findall(text)
            for match in matches:
                # Check if already captured
                existing = [s for s in parsed.secrets if s.value == match]
                if not existing and match:
                    parsed.secrets.append(ExtractedSecret(
                        type=secret_type,
                        value=match if isinstance(match, str) else match[0],
                        context='Extracted from tool output',
                    ))
