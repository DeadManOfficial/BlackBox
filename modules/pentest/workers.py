"""
Worker Pool for DeadMan Pen.

Async worker pool for parallel tool execution with:
- Rate limiting per target
- Tool dependencies
- Real-time result aggregation
- Constraint enforcement
"""

import asyncio
import time
from dataclasses import dataclass, field
from typing import Any, Callable, Dict, List, Optional, Set
from datetime import datetime, timedelta
from collections import defaultdict
from enum import Enum


class TaskPriority(Enum):
    """Task priority levels."""
    CRITICAL = 0
    HIGH = 1
    NORMAL = 2
    LOW = 3


class TaskStatus(Enum):
    """Task execution status."""
    PENDING = 'pending'
    RUNNING = 'running'
    COMPLETED = 'completed'
    FAILED = 'failed'
    CANCELLED = 'cancelled'
    RATE_LIMITED = 'rate_limited'


@dataclass
class ToolTask:
    """Represents a tool execution task."""
    id: str
    tool: str
    params: Dict[str, Any]
    priority: TaskPriority = TaskPriority.NORMAL
    timeout: int = 60000  # milliseconds
    depends_on: List[str] = field(default_factory=list)
    callback: Optional[Callable] = None
    created_at: datetime = field(default_factory=datetime.now)


@dataclass
class TaskResult:
    """Result of a tool task execution."""
    task_id: str
    tool: str
    status: TaskStatus
    data: Dict[str, Any] = field(default_factory=dict)
    error: Optional[str] = None
    duration_ms: int = 0
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None


@dataclass
class RateLimitConfig:
    """Rate limiting configuration."""
    requests_per_second: float = 10.0
    burst_size: int = 20
    window_seconds: int = 60


@dataclass
class Scope:
    """Target scope configuration."""
    allowed_domains: Set[str] = field(default_factory=set)
    blocked_paths: Set[str] = field(default_factory=set)
    blocked_actions: Set[str] = field(default_factory=set)


@dataclass
class TimeWindow:
    """Time window for operations."""
    enabled: bool = False
    allowed_hours: List[int] = field(default_factory=lambda: list(range(24)))
    timezone: str = 'UTC'


class TokenBucket:
    """Token bucket for rate limiting."""

    def __init__(self, rate: float, capacity: int):
        self.rate = rate
        self.capacity = capacity
        self.tokens = capacity
        self.last_update = time.time()
        self._lock = asyncio.Lock()

    async def acquire(self, tokens: int = 1) -> bool:
        """Acquire tokens from the bucket."""
        async with self._lock:
            now = time.time()
            elapsed = now - self.last_update
            self.tokens = min(self.capacity, self.tokens + elapsed * self.rate)
            self.last_update = now

            if self.tokens >= tokens:
                self.tokens -= tokens
                return True
            return False

    async def wait_for_token(self, tokens: int = 1) -> None:
        """Wait until tokens are available."""
        while not await self.acquire(tokens):
            wait_time = (tokens - self.tokens) / self.rate
            await asyncio.sleep(min(wait_time, 1.0))


class WorkerPool:
    """
    Async worker pool for parallel tool execution.

    Features:
    - Respects rate limits per target
    - Handles tool dependencies
    - Aggregates results in real-time
    - Enforces operational constraints
    """

    def __init__(self, max_workers: int = 10, rate_limit: RateLimitConfig = None):
        """Initialize worker pool."""
        self.max_workers = max_workers
        self.rate_limit = rate_limit or RateLimitConfig()

        self._task_queue: asyncio.PriorityQueue = asyncio.PriorityQueue()
        self._results: Dict[str, TaskResult] = {}
        self._running_tasks: Set[str] = set()
        self._completed_tasks: Set[str] = set()
        self._cancelled = False

        self._token_bucket = TokenBucket(
            rate=self.rate_limit.requests_per_second,
            capacity=self.rate_limit.burst_size
        )

        self._scope: Optional[Scope] = None
        self._time_window: Optional[TimeWindow] = None

        self._tool_executor: Optional[Callable] = None
        self._result_callbacks: List[Callable] = []

    def set_constraints(self, rate_limit: RateLimitConfig = None,
                        time_window: TimeWindow = None,
                        scope: Scope = None) -> None:
        """Configure operational constraints."""
        if rate_limit:
            self.rate_limit = rate_limit
            self._token_bucket = TokenBucket(
                rate=rate_limit.requests_per_second,
                capacity=rate_limit.burst_size
            )

        if time_window:
            self._time_window = time_window

        if scope:
            self._scope = scope

    def set_tool_executor(self, executor: Callable) -> None:
        """Set the function that executes tools."""
        self._tool_executor = executor

    def add_result_callback(self, callback: Callable) -> None:
        """Add callback for when results are received."""
        self._result_callbacks.append(callback)

    async def submit(self, task: ToolTask) -> str:
        """Submit a task to the pool."""
        # Validate against scope
        if self._scope and not self._validate_scope(task):
            self._results[task.id] = TaskResult(
                task_id=task.id,
                tool=task.tool,
                status=TaskStatus.CANCELLED,
                error='Task outside scope'
            )
            return task.id

        # Check time window
        if self._time_window and not self._check_time_window():
            self._results[task.id] = TaskResult(
                task_id=task.id,
                tool=task.tool,
                status=TaskStatus.RATE_LIMITED,
                error='Outside allowed time window'
            )
            return task.id

        # Add to queue with priority
        priority = (task.priority.value, task.created_at.timestamp())
        await self._task_queue.put((priority, task))

        return task.id

    async def execute_batch(self, tasks: List[ToolTask],
                            max_concurrent: int = None) -> List[TaskResult]:
        """
        Execute multiple tools concurrently.

        Args:
            tasks: List of tasks to execute
            max_concurrent: Override max concurrent (default: self.max_workers)

        Returns:
            List of TaskResults in order of completion
        """
        if not self._tool_executor:
            raise RuntimeError("Tool executor not set. Call set_tool_executor first.")

        max_concurrent = max_concurrent or self.max_workers
        semaphore = asyncio.Semaphore(max_concurrent)
        results = []

        # Build dependency graph
        task_map = {t.id: t for t in tasks}
        completed_deps: Set[str] = set()

        async def execute_with_deps(task: ToolTask) -> TaskResult:
            # Wait for dependencies
            while task.depends_on:
                pending_deps = [d for d in task.depends_on if d not in completed_deps]
                if not pending_deps:
                    break
                await asyncio.sleep(0.1)

            # Acquire semaphore and rate limit
            async with semaphore:
                await self._token_bucket.wait_for_token()

                # Execute
                result = await self._execute_task(task)
                completed_deps.add(task.id)
                results.append(result)

                # Notify callbacks
                for callback in self._result_callbacks:
                    try:
                        callback(result)
                    except Exception:
                        pass

                return result

        # Execute all tasks
        await asyncio.gather(
            *[execute_with_deps(task) for task in tasks],
            return_exceptions=True
        )

        return results

    async def _execute_task(self, task: ToolTask) -> TaskResult:
        """Execute a single task."""
        self._running_tasks.add(task.id)
        started_at = datetime.now()

        try:
            # Execute with timeout
            result_data = await asyncio.wait_for(
                self._tool_executor(task.tool, task.params),
                timeout=task.timeout / 1000
            )

            completed_at = datetime.now()
            duration_ms = int((completed_at - started_at).total_seconds() * 1000)

            result = TaskResult(
                task_id=task.id,
                tool=task.tool,
                status=TaskStatus.COMPLETED,
                data=result_data if isinstance(result_data, dict) else {'result': result_data},
                duration_ms=duration_ms,
                started_at=started_at,
                completed_at=completed_at
            )

        except asyncio.TimeoutError:
            result = TaskResult(
                task_id=task.id,
                tool=task.tool,
                status=TaskStatus.FAILED,
                error=f'Timeout after {task.timeout}ms',
                started_at=started_at,
                completed_at=datetime.now()
            )

        except Exception as e:
            result = TaskResult(
                task_id=task.id,
                tool=task.tool,
                status=TaskStatus.FAILED,
                error=str(e),
                started_at=started_at,
                completed_at=datetime.now()
            )

        finally:
            self._running_tasks.discard(task.id)
            self._completed_tasks.add(task.id)

        self._results[task.id] = result

        # Execute callback if provided
        if task.callback:
            try:
                task.callback(result)
            except Exception:
                pass

        return result

    def _validate_scope(self, task: ToolTask) -> bool:
        """Validate task against scope constraints."""
        if not self._scope:
            return True

        # Check blocked paths
        url = task.params.get('url') or task.params.get('targetUrl') or ''
        for blocked in self._scope.blocked_paths:
            if blocked in url:
                return False

        # Check blocked actions
        if task.tool in self._scope.blocked_actions:
            return False

        # Check allowed domains
        if self._scope.allowed_domains:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            if parsed.netloc and parsed.netloc not in self._scope.allowed_domains:
                # Check if subdomain of allowed domain
                is_subdomain = any(
                    parsed.netloc.endswith('.' + domain)
                    for domain in self._scope.allowed_domains
                )
                if not is_subdomain:
                    return False

        return True

    def _check_time_window(self) -> bool:
        """Check if current time is within allowed window."""
        if not self._time_window or not self._time_window.enabled:
            return True

        current_hour = datetime.now().hour
        return current_hour in self._time_window.allowed_hours

    def get_result(self, task_id: str) -> Optional[TaskResult]:
        """Get result for a specific task."""
        return self._results.get(task_id)

    def get_all_results(self) -> Dict[str, TaskResult]:
        """Get all results."""
        return dict(self._results)

    def get_pending_count(self) -> int:
        """Get number of pending tasks."""
        return self._task_queue.qsize()

    def get_running_count(self) -> int:
        """Get number of running tasks."""
        return len(self._running_tasks)

    def get_completed_count(self) -> int:
        """Get number of completed tasks."""
        return len(self._completed_tasks)

    def cancel_all(self) -> None:
        """Cancel all pending tasks."""
        self._cancelled = True
        # Clear queue
        while not self._task_queue.empty():
            try:
                self._task_queue.get_nowait()
            except asyncio.QueueEmpty:
                break

    def reset(self) -> None:
        """Reset the worker pool."""
        self._task_queue = asyncio.PriorityQueue()
        self._results.clear()
        self._running_tasks.clear()
        self._completed_tasks.clear()
        self._cancelled = False


class TaskScheduler:
    """
    Advanced task scheduler with dependency resolution and priority handling.
    """

    def __init__(self, worker_pool: WorkerPool):
        self.pool = worker_pool
        self._dependency_graph: Dict[str, Set[str]] = defaultdict(set)
        self._reverse_deps: Dict[str, Set[str]] = defaultdict(set)

    def add_task(self, task: ToolTask) -> None:
        """Add task with dependency tracking."""
        for dep in task.depends_on:
            self._dependency_graph[task.id].add(dep)
            self._reverse_deps[dep].add(task.id)

    def get_ready_tasks(self, completed: Set[str]) -> List[str]:
        """Get tasks with all dependencies satisfied."""
        ready = []
        for task_id, deps in self._dependency_graph.items():
            if task_id not in completed and deps.issubset(completed):
                ready.append(task_id)
        return ready

    def topological_sort(self, task_ids: List[str]) -> List[str]:
        """Sort tasks in dependency order."""
        visited = set()
        result = []

        def visit(task_id: str) -> None:
            if task_id in visited:
                return
            visited.add(task_id)
            for dep in self._dependency_graph.get(task_id, set()):
                visit(dep)
            result.append(task_id)

        for task_id in task_ids:
            visit(task_id)

        return result
